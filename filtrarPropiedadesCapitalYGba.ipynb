{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En datos/properati deben estar todos los archivos de ventas provistos por properati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesProperati = filter( lambda f: not f.startswith('.'), os.listdir(\"datos/properati\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataframes = []\n",
    "#Este diccionario es para luego eliminar segun fechas erroneas\n",
    "for file_name in filesProperati:\n",
    "    \n",
    "    newDataFrame = pd.read_csv(\"datos/properati/\"+file_name)\n",
    "    dataframes.append(newDataFrame)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Como filtramos por las zonas pedidas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros con valor nulo en state_name: 0\n",
      "Cantidad de registros con valor nulo en place_w_parent_names: 0\n",
      "Cantidad de archivos que no cuentan con la columna state_name: 26\n",
      "Cantidad de archivos que no cuentan con la columna place_w_parent_names: 0\n"
     ]
    }
   ],
   "source": [
    "nulosStateName = 0\n",
    "nulosPlaceWParentNames = 0\n",
    "noCuentaConStateName = 0\n",
    "noCuentaConPlaceWParentNames = 0\n",
    "for df in dataFrames:\n",
    "    try:\n",
    "        nulosStateName += df.state_name.isnull().sum()\n",
    "    except:\n",
    "        noCuentaConStateName += 1\n",
    "    try:\n",
    "        nulosPlaceWParentNames += df.place_with_parent_names.isnull().sum()\n",
    "    except:\n",
    "        noCuentaConPlaceWParentNames += 1\n",
    "print \"Cantidad de registros con valor nulo en state_name: \"+str(nulosStateName)\n",
    "print \"Cantidad de registros con valor nulo en place_w_parent_names: \"+str(nulosPlaceWParentNames)\n",
    "print \"Cantidad de archivos que no cuentan con la columna state_name: \"+str(noCuentaConStateName)\n",
    "print \"Cantidad de archivos que no cuentan con la columna place_w_parent_names: \"+str(noCuentaConPlaceWParentNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dado los resultados, para quedarnos solo con las propiedades de Capital Federal y GBA tendremos que utilizar la columna 'place_with_parent_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frecuencias = {}\n",
    "for df in dataFrames:\n",
    "    parentNames = df['place_with_parent_names']\n",
    "    for padres in parentNames:\n",
    "        zona = padres.split(\"|\")[2]\n",
    "        if zona not in frecuencias:\n",
    "            frecuencias[zona] = 1\n",
    "        else:\n",
    "            frecuencias[zona]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuquén 3073\n",
      "Córdoba 28847\n",
      "Chaco 303\n",
      "Mendoza 2163\n",
      "Chubut 612\n",
      "Capital Federal 172817\n",
      "San Luis 2424\n",
      "Tucumán 1220\n",
      "Misiones 2274\n",
      "Tierra Del Fuego 484\n",
      "Bs.As. G.B.A. Zona Oeste 92161\n",
      "Corrientes 826\n",
      "Formosa 254\n",
      "Río Negro 6387\n",
      "Santa Cruz 84\n",
      "Montevideo 3\n",
      "La Pampa 1002\n",
      "Buenos Aires Costa Atlántica 47635\n",
      "Buenos Aires Interior 15792\n",
      "Bs.As. G.B.A. Zona Sur 50812\n",
      "Santiago Del Estero 25\n",
      "Jujuy 100\n",
      "Santa Fe 32650\n",
      "Salta 2286\n",
      "La Rioja 52\n",
      "Entre Ríos 5574\n",
      "Bs.As. G.B.A. Zona Norte 142283\n",
      "Catamarca 114\n",
      "San Juan 116\n"
     ]
    }
   ],
   "source": [
    "for zona in frecuencias: \n",
    "    print zona,frecuencias[zona]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interesan: Bs.As. G.B.A. Zona Norte, Bs.As. G.B.A. Zona Sur, Bs.As. G.B.A. Zona Oeste, Capital Federal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filtrarCapitalYGBA(serie):\n",
    "    deseados = [\"Bs.As. G.B.A. Zona Norte\", \"Bs.As. G.B.A. Zona Sur\", \"Bs.As. G.B.A. Zona Oeste\", \"Capital Federal\"]\n",
    "    booleans = []\n",
    "    for item in serie:\n",
    "        if item.split(\"|\")[2] in deseados:\n",
    "            booleans.append(True)\n",
    "        else:\n",
    "            booleans.append(False)\n",
    "    return booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtrados =[]\n",
    "for df in dataFrames:\n",
    "    \n",
    "    df = df[filtrarCapitalYGBA(df['place_with_parent_names'])]\n",
    "    filtrados.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Por las dudas chequeo que ahora las frecuencias sean las mismas y solo queden las zonas que interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frecuencias = {}\n",
    "for df in filtrados:\n",
    "    parentNames = df['place_with_parent_names']\n",
    "    for padres in parentNames:\n",
    "        zona = padres.split(\"|\")[2]\n",
    "        if zona not in frecuencias:\n",
    "            frecuencias[zona] = 1\n",
    "        else:\n",
    "            frecuencias[zona]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital Federal 172817\n",
      "Bs.As. G.B.A. Zona Norte 142283\n",
      "Bs.As. G.B.A. Zona Oeste 92161\n",
      "Bs.As. G.B.A. Zona Sur 50812\n"
     ]
    }
   ],
   "source": [
    "for key in frecuencias:\n",
    "    print key, frecuencias[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora recupero datos, elimino algunas columnas, y demas.\n",
    "# Primero miro como estan los datos, para ver si conviene trabajar con los precios en pesos argentinos o dolares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def a(df, column_name):\n",
    "    try:\n",
    "        return(df[column_name].isnull().sum(),0)\n",
    "    except:\n",
    "        return (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nulsPriceAproxLocalCurr = 0\n",
    "nulsPriceAproxUsd = 0\n",
    "nulsPricePerM2 = 0\n",
    "nulsPricePerM2usd = 0\n",
    "\n",
    "priceAproxLocalCurrInex = 0\n",
    "priceAproxUsdInex = 0\n",
    "pricePerM2Inex = 0\n",
    "pricePerM2usdInex = 0\n",
    "\n",
    "for df in filtrados:\n",
    "    nuls, inex = a(df, \"price_aprox_local_currency\")\n",
    "    nulsPriceAproxLocalCurr += nuls\n",
    "    priceAproxLocalCurrInex += inex\n",
    "    nuls,inex = a(df, \"price_aprox_usd\")\n",
    "    nulsPriceAproxUsd += nuls\n",
    "    priceAproxUsdInex += inex\n",
    "    nuls, inex = a(df, \"price_per_m2\")\n",
    "    nulsPricePerM2 += nuls\n",
    "    pricePerM2Inex += inex\n",
    "    nuls,inex = a(df, \"price_usd_per_m2\")\n",
    "    nulsPricePerM2usd += nuls\n",
    "    pricePerM2usdInex += inex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58927 Nulls priceAproxLocalCurr\n",
      "58927 Nulls priceAproxUsd\n",
      "32915 Nulls Price Per M2\n",
      "150676 Nulls pricePerM2USD\n",
      "0 Inexistentes priceAproxLocalCurr\n",
      "0 Inexistentes priceAproxUsd\n",
      "26 Inexistentes pricePerM2\n",
      "0 Inexistentes pricePerM2usd\n"
     ]
    }
   ],
   "source": [
    "print str(nulsPriceAproxLocalCurr)+\" Nulls priceAproxLocalCurr\"\n",
    "print str(nulsPriceAproxUsd)+\" Nulls priceAproxUsd\"\n",
    "print str(nulsPricePerM2)+\" Nulls Price Per M2\"\n",
    "print str(nulsPricePerM2usd)+\" Nulls pricePerM2USD\"\n",
    "print str(priceAproxLocalCurrInex)+\" Inexistentes priceAproxLocalCurr\"\n",
    "print str(priceAproxUsdInex)+\" Inexistentes priceAproxUsd\"\n",
    "print str(pricePerM2Inex)+\" Inexistentes pricePerM2\"\n",
    "print str(pricePerM2usdInex)+\" Inexistentes pricePerM2usd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tambien miro los datos acerca de las superficies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observo que algunos archivos solo tienen una columna 'surface_in_m2', no distingue entre si es cubierta o si es total, suponemos que es la superficie total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101233"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulsSuperficieTotal = 0\n",
    "for df in filtrados:\n",
    "    try:\n",
    "        nulsSuperficieTotal += df.surface_in_m2.isnull().sum()\n",
    "    except:\n",
    "        nulsSuperficieTotal += df.surface_total_in_m2.isnull().sum()\n",
    "nulsSuperficieTotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperamos lo que podemos de cada registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero le pongo el mismo nombre a la superficie total\n",
    "for df in filtrados:\n",
    "    try:\n",
    "        df['surface_total_in_m2']\n",
    "    except:\n",
    "        df.rename(columns={'surface_in_m2':'surface_total_in_m2'},inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recupero la informacion que pueda, precios en dolares y superficie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import recuperar_superficie,recuperar_precio_usd,recuperar_ppm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/tomas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/tomas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for df in filtrados:\n",
    "     df['surface_total_in_m2'] = df.apply(lambda row: recuperar_superficie(row),axis=1)\n",
    "     df['price_aprox_usd'] = df.apply(lambda row: recuperar_precio_usd(row),axis=1)\n",
    "     df['price_usd_per_m2'] = df.apply(lambda row: recuperar_ppm2(row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chequeo que se hayan recuperado datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58664 nuls priceAproxUsd\n",
      "101233 nuls surface_total_in_m2\n",
      "143935 nuls pricePerM2usd\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "c = 0\n",
    "for df in filtrados:\n",
    "    a += df.price_aprox_usd.isnull().sum()\n",
    "    b += df.price_usd_per_m2.isnull().sum()\n",
    "    c += df.surface_total_in_m2.isnull().sum()\n",
    "\n",
    "print str(a)+\" nuls priceAproxUsd\"\n",
    "print str(c)+\" nuls surface_total_in_m2\"\n",
    "print str(b)+\" nuls pricePerM2usd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se recuperaron datos acerca del precio aproximado en usd y el precio por m2 en usd. No se pudieron recuperar nuevos datos acerca de la superficie total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A continuacion unifico y voy eliminando duplicados, teniendo en cuenta distintos subgrupos de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unificacion = pd.concat(filtrados, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458073"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino los registros que tengan todas las columnas identicas\n",
    "a = unificacion.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409127"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Elimino registros con misma url de properati (exceptuando a los nulos)\n",
    "b = a[(~a.duplicated(subset=['properati_url'])) | (a['properati_url'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213869"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elimino duplicados \n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si estan en el mismo lugar, tienen mismo precio y descripcion, son los mismos? \n",
    "c = b.drop_duplicates(subset=[\"place_with_parent_names\",\"price_aprox_usd\",\"property_type\",\"surface_total_in_m2\",\"description\",\"created_on\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c.drop_duplicates(subset = [\"created_on\",\"title\",\"description\",\"lat\",\"lon\",\"place_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186173"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13179"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.price.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13161"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.price_aprox_usd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13179"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.price_aprox_local_currency.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimino columnas con informacion redundantes o que no interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'country_name', u'created_on', u'currency', u'description',\n",
       "       u'expenses', u'extra', u'floor', u'geonames_id', u'id',\n",
       "       u'image_thumbnail', u'lat', u'lat-lon', u'lon', u'operation',\n",
       "       u'place_name', u'place_with_parent_names', u'price',\n",
       "       u'price_aprox_local_currency', u'price_aprox_usd', u'price_per_m2',\n",
       "       u'price_usd_per_m2', u'properati_url', u'property_type', u'rooms',\n",
       "       u'state_name', u'surface_covered_in_m2', u'surface_total_in_m2',\n",
       "       u'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "d.drop([\"properati_url\", \"image_thumbnail\",\"country_name\", \"lat\",\"lon\",\"operation\",\"price_aprox_local_currency\",\"price_per_m2\",\"price\",\"currency\"], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.to_csv(\"datosCabaYGBA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
